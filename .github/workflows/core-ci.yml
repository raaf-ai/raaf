name: Core CI

on:
  push:
    branches: [ main, develop ]
    paths: 
      - 'core/**'
      - '.github/workflows/core-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'core/**'
      - '.github/workflows/core-ci.yml'

# Workflow Structure:
# 1. Lint & Style + Unit Tests (parallel foundation)
# 2. Integration, Compliance, Performance & Cost Tests (parallel comprehensive)
# 3. Acceptance Tests (validates all parallel tests passed)
# 4. Build & Summary (final validation and reporting)
env:
  RUBY_VERSION: '3.4.5'

jobs:
  # Stage 1: Basic validation (fastest feedback)
  lint:
    name: "üîç Lint & Style"
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run RuboCop (Core gem)
      run: |
        cd core
        bundle exec rubocop

    - name: Check bundle audit (Core gem)
      run: |
        cd core
        gem install bundler-audit
        bundle audit check --update

  # Stage 2: Unit tests (core functionality)
  unit-tests:
    name: "üß™ Unit Tests"
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: true
      matrix:
        ruby-version: ['3.2', '3.3', '3.4.5']
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby ${{ matrix.ruby-version }}
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run unit tests, models, and edge cases (Core gem)
      run: |
        cd core
        bundle exec rspec --tag ~integration --tag ~performance --tag ~cost --tag ~acceptance --tag ~compliance \
                         --format progress \
                         --format RspecJunitFormatter \
                         --out test-results-unit.xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}

    - name: Upload unit test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results-${{ matrix.ruby-version }}
        path: core/test-results-unit.xml

    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-reports-${{ matrix.ruby-version }}
        path: |
          core/coverage/
          !core/coverage/assets/

  # Stage 3: Parallel comprehensive tests (run simultaneously after unit tests)
  example-validation:
    name: "üìù Example Validation"
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Validate core examples
      run: |
        cd core
        bundle exec ruby scripts/validate_examples.rb
      env:
        CI: true
        RAAF_TEST_MODE: true
        # Note: Using test mode to avoid requiring real API keys in CI
        # This validates example structure and basic functionality

    - name: Upload example validation report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: example-validation-report
        path: core/example_validation_report.json

  integration-tests:
    name: "üîó Integration Tests"
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run integration tests (Core gem)
      run: |
        cd core
        bundle exec rspec --tag integration \
                         --format progress \
                         --format RspecJunitFormatter \
                         --out test-results-integration.xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}

    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: core/test-results-integration.xml

  compliance-tests:
    name: "üìã Compliance Tests"
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run compliance tests (Core gem)
      run: |
        cd core
        bundle exec rspec --tag compliance \
                         --format progress \
                         --format RspecJunitFormatter \
                         --out test-results-compliance.xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}

    - name: Upload compliance test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: compliance-test-results
        path: core/test-results-compliance.xml

  # Stage 4: Acceptance tests (end-to-end scenarios) - depends on all parallel tests
  acceptance-tests:
    name: "‚úÖ Acceptance Tests"
    runs-on: ubuntu-latest
    needs: [example-validation, integration-tests, compliance-tests, performance-tests, cost-tests]
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run acceptance tests (Core gem)
      run: |
        cd core
        bundle exec rspec --tag acceptance \
                         --format progress \
                         --format RspecJunitFormatter \
                         --out test-results-acceptance.xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}

    - name: Upload acceptance test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: acceptance-test-results
        path: core/test-results-acceptance.xml

  # Stage 5: Build verification (package validation)
  build:
    name: "üì¶ Build Gem"
    runs-on: ubuntu-latest
    needs: acceptance-tests  # Build after acceptance tests pass
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Build gem (Core gem)
      run: |
        cd core
        gem build raaf-core.gemspec

    - name: Validate gem (Core gem)
      run: |
        cd core
        gem install --local raaf-core-*.gem
        ruby -r raaf-core -e "puts 'Core gem loads successfully'"

    - name: Upload gem artifact
      uses: actions/upload-artifact@v4
      with:
        name: raaf-core-gem
        path: core/raaf-core-*.gem

  performance-tests:
    name: "‚ö° Performance Tests"
    runs-on: ubuntu-latest
    needs: unit-tests
    continue-on-error: true  # Don't fail CI if performance tests are flaky
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run performance tests (Core gem)
      run: |
        cd core
        bundle exec rspec --tag performance \
                         --format progress \
                         --format RspecJunitFormatter \
                         --out test-results-performance.xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}

    - name: Upload performance test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-test-results
        path: core/test-results-performance.xml

  cost-tests:
    name: "üí∞ Cost Analysis Tests"
    runs-on: ubuntu-latest
    needs: unit-tests
    continue-on-error: true  # Don't fail CI if cost tests are flaky
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true

    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install

    - name: Run cost analysis tests (Core gem)
      run: |
        cd core
        bundle exec rspec --tag cost \
                         --format progress \
                         --format RspecJunitFormatter \
                         --out test-results-cost.xml
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}

    - name: Upload cost test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: cost-test-results
        path: core/test-results-cost.xml

  # Final status job - summarizes all results
  test-summary:
    name: "üìä Test Summary"
    runs-on: ubuntu-latest
    needs: [acceptance-tests]
    if: always()
    
    steps:
    - uses: actions/checkout@v4

    - name: Download coverage reports
      uses: actions/download-artifact@v4
      with:
        pattern: coverage-reports-*
        path: coverage-artifacts/
        merge-multiple: false
      continue-on-error: true

    - name: Process coverage data
      id: coverage
      run: |
        echo "Processing coverage reports..."
        
        # Find the primary coverage report (use 3.4.5 as primary, fallback to first available)
        PRIMARY_COVERAGE=""
        if [ -d "coverage-artifacts/coverage-reports-3.4.5" ]; then
          PRIMARY_COVERAGE="coverage-artifacts/coverage-reports-3.4.5"
        else
          PRIMARY_COVERAGE=$(find coverage-artifacts -name "coverage-reports-*" -type d | head -1)
        fi
        
        if [ -n "$PRIMARY_COVERAGE" ] && [ -f "$PRIMARY_COVERAGE/.last_run.json" ]; then
          # Extract coverage percentage from SimpleCov's last_run.json
          COVERAGE_PERCENT=$(cat "$PRIMARY_COVERAGE/.last_run.json" | jq -r '.result.line // 0' | cut -d. -f1)
          echo "coverage_percent=$COVERAGE_PERCENT" >> $GITHUB_OUTPUT
          
          # Count covered and total lines
          if [ -f "$PRIMARY_COVERAGE/.resultset.json" ]; then
            TOTAL_LINES=$(cat "$PRIMARY_COVERAGE/.resultset.json" | jq -r '
              [.. | objects | select(has("coverage")) | .coverage | to_entries[] | .value] 
              | map(select(. != null)) | length'
            )
            COVERED_LINES=$(cat "$PRIMARY_COVERAGE/.resultset.json" | jq -r '
              [.. | objects | select(has("coverage")) | .coverage | to_entries[] | .value] 
              | map(select(. != null and . > 0)) | length'
            )
            echo "total_lines=$TOTAL_LINES" >> $GITHUB_OUTPUT
            echo "covered_lines=$COVERED_LINES" >> $GITHUB_OUTPUT
          fi
          
          echo "coverage_available=true" >> $GITHUB_OUTPUT
        else
          echo "coverage_available=false" >> $GITHUB_OUTPUT
          echo "No coverage data found"
        fi
      continue-on-error: true

    - name: Check test results
      run: |
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.acceptance-tests.result }}" == "success" ]]; then
          echo "‚úÖ **All Tests PASSED** (Lint, Unit, Integration, Compliance, Performance, Cost & Acceptance)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üéâ The acceptance tests validate that all prerequisite tests have passed successfully!" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå **Tests FAILED** - Acceptance tests did not pass" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚ö†Ô∏è This means one or more of the prerequisite tests (Lint, Unit, Integration, Compliance, Performance, Cost) failed." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## üìä Test Coverage Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ steps.coverage.outputs.coverage_available }}" == "true" ]]; then
          COVERAGE_PERCENT="${{ steps.coverage.outputs.coverage_percent }}"
          TOTAL_LINES="${{ steps.coverage.outputs.total_lines }}"
          COVERED_LINES="${{ steps.coverage.outputs.covered_lines }}"
          
          # Coverage status emoji
          if (( COVERAGE_PERCENT >= 90 )); then
            COVERAGE_EMOJI="üü¢"
          elif (( COVERAGE_PERCENT >= 80 )); then
            COVERAGE_EMOJI="üü°"
          else
            COVERAGE_EMOJI="üî¥"
          fi
          
          echo "${COVERAGE_EMOJI} **Overall Coverage: ${COVERAGE_PERCENT}%**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Lines Covered:** ${COVERED_LINES}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Lines:** ${TOTAL_LINES}" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage Threshold:** 80% minimum" >> $GITHUB_STEP_SUMMARY
          
          # Coverage quality assessment
          if (( COVERAGE_PERCENT >= 80 )); then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚úÖ Coverage meets the minimum threshold requirement!" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚ö†Ô∏è Coverage is below the minimum threshold of 80%" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "‚ö†Ô∏è Coverage data not available" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "üìã **Workflow Structure:**" >> $GITHUB_STEP_SUMMARY
        echo "1. Lint & Style + Unit Tests (parallel foundation)" >> $GITHUB_STEP_SUMMARY
        echo "2. Integration, Compliance, Performance & Cost Tests (parallel comprehensive)" >> $GITHUB_STEP_SUMMARY
        echo "3. Acceptance Tests (validates all parallel tests passed)" >> $GITHUB_STEP_SUMMARY
        echo "4. Build Gem (depends on Acceptance Tests)" >> $GITHUB_STEP_SUMMARY
        echo "5. Test Summary (depends on Acceptance Tests)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Performance and Cost tests run in parallel but may continue-on-error." >> $GITHUB_STEP_SUMMARY

    - name: Fail if acceptance tests failed
      if: needs.acceptance-tests.result != 'success'
      run: |
        echo "‚ùå Acceptance tests failed, indicating issues with prerequisite tests. See summary above."
        exit 1

  # Coverage comparison job - fails PR if coverage decreases
  coverage-check:
    name: "üìä Coverage Check"
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for base comparison
    
    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ env.RUBY_VERSION }}
        bundler-cache: true
    
    - name: Install dependencies (Core gem)
      run: |
        cd core
        bundle install
    
    - name: Download current PR coverage
      uses: actions/download-artifact@v4
      with:
        name: coverage-reports-${{ env.RUBY_VERSION }}
        path: pr-coverage/
    
    - name: Get base branch coverage
      run: |
        echo "Getting base branch coverage for comparison..."
        cd core
        
        # Switch to base branch and run tests to get baseline coverage
        git checkout ${{ github.event.pull_request.base.sha }}
        
        # Run tests to generate baseline coverage
        CI=true bundle exec rspec \
          --tag ~integration --tag ~performance --tag ~cost --tag ~acceptance \
          --format progress \
          --quiet
        
        # Save base coverage data
        mkdir -p ../base-coverage
        cp -r coverage/* ../base-coverage/ 2>/dev/null || echo "No base coverage to copy"
        
        # Switch back to PR branch
        git checkout ${{ github.sha }}
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}
    
    - name: Compare coverage and fail if decreased
      id: coverage-comparison
      run: |
        echo "Comparing coverage between base branch and PR..."
        
        # Extract PR coverage
        if [ -f "pr-coverage/.last_run.json" ]; then
          PR_COVERAGE=$(cat pr-coverage/.last_run.json | jq -r '.result.line // 0')
          echo "PR Coverage: ${PR_COVERAGE}%"
        else
          echo "‚ùå PR coverage data not found"
          exit 1
        fi
        
        # Extract base coverage
        if [ -f "base-coverage/.last_run.json" ]; then
          BASE_COVERAGE=$(cat base-coverage/.last_run.json | jq -r '.result.line // 0')
          echo "Base Coverage: ${BASE_COVERAGE}%"
        else
          echo "‚ö†Ô∏è Base coverage data not found, using 0% as baseline"
          BASE_COVERAGE=0
        fi
        
        # Calculate difference using awk (more portable than bc)
        COVERAGE_DIFF=$(awk "BEGIN {printf \"%.2f\", $PR_COVERAGE - $BASE_COVERAGE}")
        
        echo "pr_coverage=$PR_COVERAGE" >> $GITHUB_OUTPUT
        echo "base_coverage=$BASE_COVERAGE" >> $GITHUB_OUTPUT
        echo "coverage_diff=$COVERAGE_DIFF" >> $GITHUB_OUTPUT
        
        echo "Coverage comparison:"
        echo "- Base branch: ${BASE_COVERAGE}%"
        echo "- PR branch: ${PR_COVERAGE}%"
        echo "- Difference: ${COVERAGE_DIFF}%"
        
        # Fail if coverage decreased by more than 0.1%
        if awk "BEGIN {exit !($COVERAGE_DIFF < -0.1)}"; then
          echo "‚ùå Coverage decreased by ${COVERAGE_DIFF#-}%"
          echo "coverage_decreased=true" >> $GITHUB_OUTPUT
          exit 1
        elif awk "BEGIN {exit !($COVERAGE_DIFF > 0.1)}"; then
          echo "‚úÖ Coverage improved by ${COVERAGE_DIFF}%"
          echo "coverage_decreased=false" >> $GITHUB_OUTPUT
        else
          echo "‚úÖ Coverage remained stable (${COVERAGE_DIFF}%)"
          echo "coverage_decreased=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Comment on PR with coverage comparison
      if: always()
      uses: actions/github-script@v7
      with:
        script: |
          const prCoverage = '${{ steps.coverage-comparison.outputs.pr_coverage }}';
          const baseCoverage = '${{ steps.coverage-comparison.outputs.base_coverage }}';
          const coverageDiff = '${{ steps.coverage-comparison.outputs.coverage_diff }}';
          const coverageDecreased = '${{ steps.coverage-comparison.outputs.coverage_decreased }}' === 'true';
          
          let emoji = '‚úÖ';
          let status = 'Coverage maintained';
          
          if (coverageDecreased) {
            emoji = '‚ùå';
            status = 'Coverage decreased';
          } else if (parseFloat(coverageDiff) > 0.1) {
            emoji = 'üéâ';
            status = 'Coverage improved';
          }
          
          const comment = `## ${emoji} Coverage Report
          
          | Metric | Base Branch | PR Branch | Change |
          |--------|-------------|-----------|---------|
          | **Line Coverage** | ${baseCoverage}% | ${prCoverage}% | ${coverageDiff > 0 ? '+' : ''}${coverageDiff}% |
          
          **Status:** ${status}
          
          ${coverageDecreased ? 
            '‚ö†Ô∏è **This PR decreases test coverage.** Please add tests to maintain or improve coverage.' : 
            '‚úÖ Coverage check passed!'}
          
          ---
          *Coverage threshold: 80% minimum | Generated by GitHub Actions*`;
          
          // Find existing coverage comment and update it, or create new one
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });
          
          const existingComment = comments.data.find(comment => 
            comment.body.includes('Coverage Report') && comment.user.type === 'Bot'
          );
          
          if (existingComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existingComment.id,
              body: comment
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });
          }